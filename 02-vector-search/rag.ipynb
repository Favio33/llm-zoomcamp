{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa755a08-b98d-4e92-8994-04e6108499d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.schema.messages import HumanMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdfb2649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859dd65f",
   "metadata": {},
   "source": [
    "# Set up LLM functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fe0426fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(question: str, search_results: list[str]):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\", \"\"\"\n",
    "                You're a course teaching assistant, consider the current date: {current_date}. Answer the QUESTION based on the CONTEXT from the FAQ database\n",
    "                Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "                CONTEXT: {context}\"\"\"\n",
    "            ),\n",
    "            (\"human\", \"{query}\"),\n",
    "            (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "            ]\n",
    "        )\n",
    "    context = ''\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    return prompt.format_messages(query=question, context=context, current_date=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e003fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_client() -> AzureChatOpenAI:\n",
    "    return AzureChatOpenAI(\n",
    "        deployment_name=\"gpt-4o-mini\",\n",
    "        model_name='gpt-4o-mini',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d2dac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_execute(llm_client: AzureChatOpenAI, prompt: list[str]) -> str:\n",
    "    response = llm_client.invoke(prompt)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e74cbca",
   "metadata": {},
   "source": [
    "# Set up vector search functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c2a2119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fce9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf1440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ai\\llm-zoomcamp\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_qdrant_client() -> QdrantClient:\n",
    "    return QdrantClient(\n",
    "        url=\"http://localhost:6333\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9281b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qdrant_collection(qdrant_client: QdrantClient,\n",
    "                             collection_name: str,\n",
    "                             embedding_dim: int,\n",
    "                             distance: models.Distance = models.Distance.COSINE,\n",
    "                             multivector: bool = False) -> None:\n",
    "\n",
    "    if qdrant_client.collection_exists(collection_name):\n",
    "        print(f\"Collection {collection_name} already exists\")\n",
    "        return None\n",
    "\n",
    "    if multivector:\n",
    "        print(\"Multivector collection is not supported yet\")\n",
    "        return None\n",
    "\n",
    "    return qdrant_client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=models.VectorParams(\n",
    "            size=embedding_dim,\n",
    "            distnance=distance\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72891e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(input_data: list[dict], model_handle: str) -> list[models.PointStruct]:\n",
    "    points = []\n",
    "\n",
    "    for i, doc in enumerate(documents):\n",
    "        text = doc['question'] + ' ' + doc['text']\n",
    "        vector = models.Document(text=text, model=model_handle)\n",
    "        point = models.PointStruct(\n",
    "            id=i,\n",
    "            vector=vector,\n",
    "            payload=doc\n",
    "        )\n",
    "        points.append(point)\n",
    "\n",
    "    return points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f2a38167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(qdrant_client: QdrantClient,\n",
    "                  collection_name: str,\n",
    "                  model_handle: str,\n",
    "                  question: str,\n",
    "                  course_target: str):\n",
    "\n",
    "    print('vector_search is used')\n",
    "    \n",
    "    query_points = qdrant_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(\n",
    "            text=question,\n",
    "            model=model_handle \n",
    "        ),\n",
    "        query_filter=models.Filter( \n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\",\n",
    "                    match=models.MatchValue(value=course_target)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=5,\n",
    "        with_payload=True\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for point in query_points.points:\n",
    "        results.append(point.payload)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3e63c8",
   "metadata": {},
   "source": [
    "# Set up RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a4a5b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(llm_client: AzureChatOpenAI, query: str, results: list[dict]) -> str:\n",
    "    search_results = results\n",
    "    prompt = generate_prompt(query, search_results)\n",
    "    answer = llm_execute(llm_client, prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455a30a1",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "09fecbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_client = get_llm_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f758584",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_handle = 'jinaai/jina-embeddings-v2-small-en'\n",
    "collection_name = 'rag-faq'\n",
    "course_match = 'data-engineering-zoomcamp'\n",
    "EMBEDDING_DIM = 512\n",
    "qdrant_client = get_qdrant_client()\n",
    "create_qdrant_collection(qdrant_client, collection_name, EMBEDDING_DIM, models.Distance.COSINE)\n",
    "vs_points = get_points(documents, model_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b08f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=vs_points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ccc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\" # exact matching on string metadata fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5732a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = 'I just discovered the course. Can I still join it?'\n",
    "question = 'how do I run kafka?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6206ca00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_search is used\n"
     ]
    }
   ],
   "source": [
    "results = vector_search(qdrant_client, collection_name, model_handle, question, course_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a545060f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how do I run kafka?'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9426322b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To run Kafka, ensure that your Kafka broker Docker container is working. You can confirm this by using the command `docker ps` to check the status of your containers. If the Kafka broker is not running, navigate to the directory containing your Docker Compose YAML file and execute `docker compose up -d` to start all the instances.\\n\\nOnce your Kafka broker is running, you can run producer, consumer, or other Java scripts (like JsonProducer.java or JsonConsumer.java) by using the following command in your project directory:\\n\\n```bash\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n```\\n\\nReplace `<jar_name>` with the actual name of your jar file. Make sure the configuration for the Kafka server URL and secrets are correctly updated in your scripts to ensure they can connect to the Kafka broker successfully.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(llm_client, question, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71154c38-cc68-4d29-9809-f0f0545c79c3",
   "metadata": {},
   "source": [
    "## RAG with Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6698670a-6fe7-4f51-83f7-281e80e06f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90bdc6f4-b6f8-4491-84f4-bbd8a6b9f6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_search is used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To run Kafka, you need to follow these steps based on your scripts:\\n\\n1. Make sure your Kafka broker is running. You can confirm this by running `docker ps`. If the broker is not active, navigate to the folder with your docker-compose yaml file and run `docker compose up -d` to start all instances.\\n\\n2. In your project directory, to run the producer, use the following command:\\n   ```\\n   java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n   ```\\n\\n3. Ensure that the `StreamsConfig.BOOTSTRAP_SERVERS_CONFIG` in your Java scripts (e.g., JsonProducer.java, JsonConsumer.java) is set to the correct server URL. Also, verify that the cluster key and secrets in `src/main/java/org/example/Secrets.java` are updated with the correct values.\\n\\nBy following these steps, you should be able to run Kafka successfully.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('how do I run kafka?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886901ee-6e55-4295-a106-af25e6483da5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
